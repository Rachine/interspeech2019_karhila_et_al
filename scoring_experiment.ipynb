{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring experiments #\n",
    "\n",
    "### Start with imports: ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### Load data: ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataurl  = \"https://github.com/aalto-speech/interspeech2019_karhila_et_al/blob/master/phone_recognition_results_v0.21.pickle?raw=true\"\n",
    "[phones, phones_to_features, hypotheses, references, scores, speakers, words, train_speakers, test_speakers] = pickle.load(urlopen(dataurl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define weighted Levenshtein distance ###\n",
    "\n",
    "This is modified by Reima Karhila from https://github.com/infoscout/weighted-levenshtein to produce a list of edit operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_edit_ops(arr1, arr2, insert_costs=None,delete_costs=None,substitute_costs=None):\n",
    "    \"\"\"\n",
    "    Calculates the Levenshtein distance between str1 and str2,\n",
    "    provided the costs of inserting, deleting, and substituting characters.\n",
    "    The costs default to 1 if not provided.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Some special cases we wouldn't like to see:\n",
    "    if len(arr1) == 0 and len(arr2) == 0:\n",
    "        print(\"arr1 and arr2 zero length, returning cost and ops:\", 0, [])\n",
    "        return 0, []\n",
    "\n",
    "    elif len(arr2) == 0:\n",
    "        path = [ ['d', i, i ] for i in arr2 ]\n",
    "        if delete_costs is not None:\n",
    "            ret_val = sum( [ delete_costs[i] for i in arr1 ] )\n",
    "        else:\n",
    "            ret_val = len(arr1)\n",
    "        print(\"arr2 zero length, returning cost and ops:\", ret_val, path)\n",
    "        return ret_val, path\n",
    "\n",
    "    elif len(arr1) == 0:\n",
    "        path = [ ['i', i, i ] for i in arr1 ]\n",
    "        if insert_costs is not None:\n",
    "            ret_val = sum( [ insertion_costs[i] for i in arr2 ] )\n",
    "        else:\n",
    "            ret_val = len(arr2)\n",
    "        print(\"arr1 zero length, returning cost and ops:\", ret_val, path)\n",
    "        return ret_val, path\n",
    "\n",
    "    maxchar = max( max(arr1), max(arr2) )\n",
    "    \n",
    "    if insert_costs is None:\n",
    "        insert_costs = np.ones([ maxchar+1 ])\n",
    "    if delete_costs is None:\n",
    "        delete_costs = np.ones([ maxchar+1 ])\n",
    "    if substitute_costs is None:\n",
    "        #print(\"Using default substitute costs\")\n",
    "        substitute_costs = np.ones([ maxchar+1,maxchar+1 ])\n",
    "\n",
    "\n",
    "    s1 = [-1] + arr1\n",
    "    s2 = [-1] + arr2\n",
    "\n",
    "    len1 = len(s1)\n",
    "    len2 = len(s2)\n",
    "    \n",
    "    op_ident = 0.0\n",
    "    op_ins = 1.0\n",
    "    op_del = 2.0\n",
    "    op_sub = 3.0\n",
    "\n",
    "    d = np.zeros([len1, len2], dtype=np.float32)\n",
    "    editops = np.zeros([len1,len2, 3], dtype=np.int)\n",
    "\n",
    "    d[0,0] = 0\n",
    "    char_i = s1[0]\n",
    "    char_j = s2[0]\n",
    "        \n",
    "    for i in range(1, len1 ):\n",
    "        char_i = s1[i]\n",
    "        d[i,0] = d[i-1,0] + delete_costs[char_i]\n",
    "        editops[i,0] = [op_del, char_i, -1]\n",
    "        \n",
    "    for j in range(1, len2):\n",
    "        char_j = s2[j]\n",
    "        #print( d[0,j-1], insert_costs[char_j])\n",
    "        d[0,j] = d[0,j-1] + insert_costs[char_j]\n",
    "        editops[0,j] = [op_ins, char_j, -1]\n",
    "        \n",
    "    for i in range(1, len1 ):\n",
    "        char_i = s1[i]\n",
    "        for j in range(1, len2):\n",
    "            char_j = s2[j]\n",
    "            #print(char_i,char_j)\n",
    "            if char_i == char_j:  # match\n",
    "                d[i,j] = d[i-1,j-1]\n",
    "                editops[i,j,:] = [op_ident, char_i, char_j]\n",
    "            else:\n",
    "                delcost = d[i-1,j] + delete_costs[char_i]\n",
    "                inscost = d[i,j-1] + insert_costs[char_j]\n",
    "                subcost = d[i-1,j-1] + substitute_costs[char_i, char_j]\n",
    "                \n",
    "                if delcost < inscost and delcost < subcost:\n",
    "                    d[i,j] = delcost\n",
    "                    editops[i,j,:] = [op_del, char_i, -1]\n",
    "                elif inscost < delcost and inscost < subcost:\n",
    "                    d[i,j] = inscost\n",
    "                    editops[i,j,:] = [op_ins, char_j, -1]\n",
    "                else:\n",
    "                    d[i,j] = subcost\n",
    "                    editops[i,j,:] = [op_sub, char_i, char_j]\n",
    "\n",
    "    ret_val = d[len1-1,len2-1]\n",
    "\n",
    "    i = len1-1\n",
    "    j = len2-1\n",
    "    path = []\n",
    "    while i > 0 or j > 0:        \n",
    "        op = editops[i,j,:]\n",
    "        if op[0] == op_sub:\n",
    "            path.append( ['s', op[1], op[2] ] )\n",
    "            i = i-1\n",
    "            j = j-1\n",
    "        elif op[0] == op_ins:\n",
    "            path.append( ['i', op[1], op[2] ] )\n",
    "            j = j-1\n",
    "        elif op[0] == op_del:\n",
    "            path.append( ['d', op[1], op[2] ] )\n",
    "            i = i-1\n",
    "        elif op[0] == op_ident:\n",
    "            i = i-1\n",
    "            j = j-1\n",
    "        \n",
    "    return ret_val, path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper data structures ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {}\n",
    "for i,p in phones.items():\n",
    "    classes[p] = i\n",
    "\n",
    "features = {}\n",
    "for feats in phones_to_features.values():\n",
    "    for feat in feats:\n",
    "        if feat not in features.keys():\n",
    "            features[feat] = len(features.keys())\n",
    "\n",
    "phonetype_counts = { 'consonant' : {}, 'vowel' : {}, 'nonspeech': {} }\n",
    "phone_stats = np.zeros([len(phones), len(features)])\n",
    "\n",
    "mean_num_features_per_phone = 0\n",
    "for p,feats in phones_to_features.items():\n",
    "    if p in classes.keys():\n",
    "        if 'vowel' in feats:\n",
    "            ptype = 'vowel'\n",
    "        elif 'consonant' in feats:\n",
    "            ptype = 'consonant'\n",
    "        else:\n",
    "            ptype = 'nonspeech'\n",
    "        for feat in feats:\n",
    "            mean_num_features_per_phone += 1\n",
    "            phonetype_counts[ptype][feat] = 1\n",
    "            phone_stats[classes[p],features[feat]] = 1\n",
    "        \n",
    "mean_num_features_per_phone /= len(phones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phone Clustering Dendogram ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Children of hierarchical clustering\n",
    "    children = model.children_\n",
    "    \n",
    "    # Distances between each pair of children\n",
    "    # Since we don't have this information, we can use a uniform one for plotting\n",
    "    distance = np.arange(children.shape[0])\n",
    "    \n",
    "    # The number of observations contained in each cluster level\n",
    "    no_of_observations = np.arange(2, children.shape[0]+2)\n",
    "    \n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "    linkage_matrix = np.column_stack([children, distance, no_of_observations]).astype(float)\n",
    "    \n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)\n",
    "    \n",
    "clustering = AgglomerativeClustering(n_clusters=len(phones))\n",
    "clustering.fit(phone_stats)\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 5]\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plot_dendrogram(clustering, labels=[ u''+i for i in phones.values()], leaf_font_size=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial phone distances ###\n",
    "\n",
    "And also a matrix for phone differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_distances = np.zeros( [len(phones),len(phones)])\n",
    "\n",
    "for i in range(len(phones)):\n",
    "    for j in range(len(phones)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        if i > j:\n",
    "            continue\n",
    "        p1 = phones_to_features[phones[i]]\n",
    "        p2 = phones_to_features[phones[j]]\n",
    "        if ('vowel' in p1 and 'vowel') in p2 or ('consonant' in p1 and 'consonant' in p2):\n",
    "            d = 0\n",
    "            for a in p1:\n",
    "                if a not in p2:\n",
    "                    d += 1\n",
    "            for a in p2:\n",
    "                if a not in p1:\n",
    "                    d += 1\n",
    "            if 'consonant' in p1:\n",
    "                dist = (d)/len(phonetype_counts['consonant'])\n",
    "            else:\n",
    "                dist = (d)/len(phonetype_counts['vowel'])\n",
    "        else:\n",
    "            dist = 1\n",
    "        phone_distances [i][j] = dist\n",
    "        phone_distances [j][i] = dist\n",
    "        \n",
    "phone_differences =  np.zeros( [len(phones),len(phones), len(features) + 1 ] )\n",
    "phone_feat_vectors = np.zeros( [len(phones), len(features)] )\n",
    "\n",
    "for i in range(len(phones)):\n",
    "    p1 = phones_to_features[phones[i]]\n",
    "    v1 = np.zeros([len(features) + 1])\n",
    "    for feat in p1:\n",
    "        v1[features[feat]] += 1 \n",
    "    phone_feat_vectors[i,:] = v1[:-1]\n",
    "    for j in range(len(phones)):\n",
    "        if i >= j:\n",
    "            continue\n",
    "        p2 = phones_to_features[phones[j]]\n",
    "        v2 = np.zeros([len(features) + 1])\n",
    "        if ('vowel' in p1 and 'vowel') in p2 or ('consonant' in p1 and 'consonant' in p2):\n",
    "            for feat in p2:\n",
    "                v2[features[feat]] += 1\n",
    "            diffv = np.logical_xor(v1,v2)\n",
    "        else:\n",
    "            diffv = np.zeros( [len(features) + 1] )\n",
    "            diffv[-1] = 1\n",
    "        phone_differences[i,j,:] = diffv\n",
    "        phone_differences[j,i,:] = diffv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial costvectors ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_costvector =  np.zeros( [len(features) + 1] )\n",
    "for ptype in ['consonant', 'vowel']:\n",
    "    for k in phonetype_counts[ptype].keys():\n",
    "        sub_costvector[features[k]] = 1/len(phonetype_counts[ptype])\n",
    "\n",
    "sub_costvector[-1] = 1    \n",
    "ins_costvector = np.ones([len(features)]) / mean_num_features_per_phone\n",
    "del_costvector = np.ones([len(features)]) / mean_num_features_per_phone\n",
    "\n",
    "\n",
    "sub_costmatrix = phone_differences.dot(sub_costvector)\n",
    "ins_costmatrix = phone_feat_vectors.dot(ins_costvector)\n",
    "del_costmatrix = phone_feat_vectors.dot(del_costvector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data and create observation matrices with initial best paths ###\n",
    "\n",
    "- Take approx 10% of train data to be our devel set\n",
    "- We'll be using the training data twice: Once with the correct reference and score, and another time with a random reference and a rejection score\n",
    "- The little progress indicator is from https://stackoverflow.com/a/41457700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refmap size: 29882\n",
      "Train items: 24236\n",
      " Test items: 4313\n",
      "Devel items: 1333\n",
      "Devel items intersect train items 0\n",
      " Test items intersect train items 0\n"
     ]
    }
   ],
   "source": [
    "train_items = np.zeros(len(speakers), dtype=np.bool)\n",
    "devel_items = np.zeros(len(speakers), dtype=np.bool)\n",
    "test_items = np.zeros(len(speakers), dtype=np.bool)\n",
    "\n",
    "for i in range(len(speakers)):\n",
    "    if speakers[i] in test_speakers:\n",
    "        test_items[i] = True\n",
    "    elif i% 10 == 0:\n",
    "        devel_items[i] = True\n",
    "    else:\n",
    "        train_items[i] = True\n",
    "\n",
    "        \n",
    "refmap = np.arange(0, len(speakers)+train_items.sum())\n",
    "refmap[len(speakers):] = np.random.permutation(np.where(train_items==True)[0])\n",
    "\n",
    "# Duplicate training data:\n",
    "devel_items = np.hstack([devel_items, np.zeros(train_items.sum()).astype(np.bool)])\n",
    "test_items = np.hstack([test_items, np.zeros(train_items.sum()).astype(np.bool)])\n",
    "train_items = np.hstack([train_items, np.ones(train_items.sum()).astype(np.bool)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nO_sub = np.zeros( [len(refmap), len(hypotheses[0]), sub_costvector.shape[0]] , dtype=np.int8 )\n",
    "nO_del = np.zeros( [len(refmap), len(hypotheses[0]), del_costvector.shape[0]] , dtype=np.int8 )\n",
    "nO_ins = np.zeros( [len(refmap), len(hypotheses[0]), ins_costvector.shape[0]] , dtype=np.int8 )\n",
    "\n",
    "least_err_indices =  np.zeros( len(refmap), dtype=np.int8 )\n",
    "ref_lengths = np.zeros( len(refmap), dtype=np.int8 )\n",
    "perfects = -np.ones( len(refmap), dtype=np.int8 )\n",
    "\n",
    "print(\"Refmap size:\", len(refmap))\n",
    "\n",
    "print(\"Train items:\", train_items.sum())\n",
    "print(\" Test items:\", test_items.sum())\n",
    "print(\"Devel items:\", devel_items.sum())\n",
    "\n",
    "print(\"Devel items intersect train items\",len(np.intersect1d(np.where(devel_items==True)[0],np.where(train_items==True)[0])))\n",
    "print(\" Test items intersect train items\",len(np.intersect1d(np.where(test_items==True)[0],np.where(train_items==True)[0])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ref \t Path \t Error \t Reference                  Best hypothesis\n",
      "0 \t 9 \t 0.54 \t lʌv                   ==>  iloːva\n",
      "1 \t 17 \t 0.06 \t ðɪs                   ==>  ðiːs\n",
      "2 \t 30 \t 0.22 \t kwaɪət                ==>  haɪət\n",
      "3 \t 43 \t 0.23 \t fiːɫd                 ==>  fɹd\n",
      "4 \t 10 \t 0.25 \t maθs                  ==>  nts\n",
      "5 \t 25 \t 0.25 \t bɔɪ                   ==>  hu\n",
      "6 \t 26 \t 0.41 \t kʰeɪk                 ==>  pk\n",
      "7 \t 15 \t 0.04 \t ɹɪvəɹ                 ==>  ɹɪvəs\n",
      "8 \t 0 \t 0.00 \t ləʊ                   ==>  ləʊ\n",
      "9 \t 23 \t 0.00 \t meɪk                  ==>  meɪk\n",
      "10 \t 17 \t 0.00 \t ʃiːp                  ==>  ʃiːp\n",
      "11 \t 23 \t 0.34 \t θaŋkjuː               ==>  lantsiːz\n",
      "12 \t 48 \t 0.24 \t wɛɫdʌn                ==>  ɹngɒn\n",
      "13 \t 35 \t 0.38 \t jʊəɹəp                ==>  reulu\n",
      "14 \t 25 \t 0.28 \t θaŋkjuː               ==>  ɪksju\n",
      "15 \t 40 \t 0.32 \t bʊk                   ==>  lk\n",
      "16 \t 24 \t 0.22 \t θɪŋ                   ==>  sɪŋə\n",
      "17 \t 31 \t 0.04 \t kʰaɹət                ==>  kʰadətʃ\n",
      "18 \t 9 \t 0.18 \t ʃəʊɫdəɹ               ==>  səʊɫda\n",
      "19 \t 42 \t 0.11 \t ðɪs                   ==>  sɪz\n",
      "\n",
      "This is pretty slow - No multi-threading, no Cython libraries etc.\n",
      "So let's use a progress bar to check how we are doing in processing 29882 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c032d643ed345aebec334d96e7dfee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=20, max=29882)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Yey!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for j in range(len(refmap)):\n",
    "    refseq = references[refmap[j]]\n",
    "    besterr = np.inf\n",
    "    bestindex = 0\n",
    "    ref_lengths[j] = len(refseq)\n",
    "    if len(refseq)>0:\n",
    "        for i in range(len(hypotheses[0])):\n",
    "            hypseq = hypotheses[ j % len(hypotheses) ][i].tolist()\n",
    "            nO_sub[j,i,:] = 0\n",
    "            nO_del[j,i,:] = 0\n",
    "            nO_ins[j,i,:] = 0\n",
    "            if len(hypseq)>0:\n",
    "                #print( ''.join([phones[k] for k in hypseq ]) )\n",
    "                cost,eops = levenshtein_edit_ops(refseq, hypseq,\n",
    "                                                 substitute_costs=sub_costmatrix,\n",
    "                                                 insert_costs=ins_costmatrix,\n",
    "                                                 delete_costs=del_costmatrix)\n",
    "                for op in eops:\n",
    "                    #print(op)\n",
    "                    if op[0] == 's':\n",
    "                        nO_sub[j,i,:] += phone_differences[op[1],op[2],:].astype(np.int8)\n",
    "                    elif op[0] == 'd':\n",
    "                        nO_del[j,i,:] += phone_feat_vectors[op[1],:].astype(np.int8)\n",
    "                    elif op[0] == 'i':\n",
    "                        nO_ins[j,i,:] += phone_feat_vectors[op[1],:].astype(np.int8)                                            \n",
    "                cost = cost/len(refseq)\n",
    "                if cost < besterr:\n",
    "                    bestindex = i\n",
    "                    besterr = cost\n",
    "                    besthyp = hypseq\n",
    "                    if len(eops) == 0:\n",
    "                        perfects[j] = bestindex\n",
    "            else:\n",
    "                for r in refseq:\n",
    "                    nO_ins[j,i,:] += phone_feat_vectors[r,:].astype(np.int8)    \n",
    "        if j == 0:\n",
    "            print(\"Ref\",'\\t', \"Path\", \"\\t\", \"Error\", '\\t', \"Reference\".ljust(20), '     ', \"Best hypothesis\" )\n",
    "        if j < 20:\n",
    "            print ( j, '\\t', bestindex,'\\t',\"%0.2f\"%besterr,'\\t',''.join([phones[k] for k in refseq ]).ljust(20),' ==> ',''.join([phones[k] for k in besthyp ]))\n",
    "        elif j == 20:\n",
    "            print(\"\")\n",
    "            print(\"This is pretty slow - No multi-threading, no Cython libraries etc.\")\n",
    "            print(\"So let's use a progress bar to check how we are doing in processing %i samples.\" % len(refmap))\n",
    "            f = IntProgress(min=0, max=len(refmap)) # instantiate the bar\n",
    "            f.value = 20\n",
    "            display(f) # display the bar\n",
    "        else:\n",
    "            f.value += 1\n",
    "        least_err_indices[j] = bestindex\n",
    "\n",
    "print(\"Done! Yey!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scores[:len(speakers)]\n",
    "inv_scores = np.zeros(len(refmap))\n",
    "inv_scores[:len(scores)] = (100-scores)/100\n",
    "inv_scores[len(scores):] = 1.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_sub = np.zeros( [len(refmap), sub_costvector.shape[0]] , dtype=np.int8 )\n",
    "O_ins = np.zeros( [len(refmap), ins_costvector.shape[0]] , dtype=np.int8 )\n",
    "O_del = np.zeros( [len(refmap), del_costvector.shape[0]] , dtype=np.int8 )\n",
    "\n",
    "sub_indices=np.arange(0, len(sub_costvector), dtype=int)\n",
    "ins_indices=np.arange(max(sub_indices)+1, max(sub_indices)+1+len(ins_costvector), dtype=int)\n",
    "del_indices=np.arange(max(ins_indices)+1, max(ins_indices)+1+len(del_costvector), dtype=int)\n",
    "warping_index = np.max(del_indices)+1\n",
    "length_compensation_index = np.max(warping_index)+1\n",
    "\n",
    "x0 = np.zeros([length_compensation_index+1])\n",
    "x0[sub_indices] = sub_costvector\n",
    "x0[ins_indices] = ins_costvector\n",
    "x0[del_indices] = del_costvector\n",
    "x0[warping_index] = 1\n",
    "x0[length_compensation_index] = 1\n",
    "\n",
    "current_train_items = train_items\n",
    "\n",
    "def tanh(x,a, scale=1.01):\n",
    "    return scale * (np.tanh(a*x))\n",
    "\n",
    "def get_error_rates(hypx, items):\n",
    "    return O_sub[items].dot(hypx[sub_indices]) + O_ins[items].dot(hypx[ins_indices]) + O_del[items].dot(hypx[del_indices])\n",
    "\n",
    "def do_computation(hypx, items):\n",
    "    hyp_scores = get_error_rates(hypx, items)\n",
    "    hyp_scores /=  (ref_lengths[items] ** hypx[length_compensation_index])\n",
    "    hyp_scores = tanh(hyp_scores, hypx[warping_index])\n",
    "    return hyp_scores\n",
    "\n",
    "def costfunction(hypx):    \n",
    "    hyp_scores = do_computation(hypx, current_train_items)\n",
    "    # Normal least squares:\n",
    "    # np.mean( (hyp_scores - inv_scores[current_train_items])**2)\n",
    "    # Cauchy norm to limit outlier influence:\n",
    "    return np.mean( (np.log(1.01 + np.abs(hyp_scores - inv_scores[current_train_items])))**2)\n",
    "\n",
    "def get_scores(hypx, items):\n",
    "    return 100-(do_computation(hypx, items)*100)\n",
    "\n",
    "\n",
    "def compute_Os(hypx, nbest_mult):\n",
    "    for i in range(len(refmap)):\n",
    "        num_nbest = np.clip( nbest_mult * ref_lengths[i], 1, len(hypotheses[ i % len(speakers) ]))\n",
    "        least_err_indices[i] = np.argmin( nO_sub[i,:num_nbest,:].dot(hypx[sub_indices]) + \\\n",
    "                                          nO_ins[i,:num_nbest,:].dot(hypx[ins_indices]) + \\\n",
    "                                          nO_del[i,:num_nbest,:].dot(hypx[del_indices]) )\n",
    "        O_sub[i,:] = nO_sub [i,least_err_indices[i],:]\n",
    "        O_ins[i,:] = nO_ins [i,least_err_indices[i],:]\n",
    "        O_del[i,:] = nO_del [i,least_err_indices[i],:]\n",
    "        if train_items[i] and (O_sub[i,:].sum() > 0 or O_del[i,:].sum() == 0):\n",
    "            current_train_items[i] = True\n",
    "        else:\n",
    "            current_train_items[i] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Driven Phoneme Weighted Levenshtein Distance #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search for optimal parameters with different N-best list lengths\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10046dd9dfc4a0abe68494e82e44c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=50)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dd-wpld best score: 0.45792060118623173\n",
      "dd-wpld best keys: [10, 2]\n"
     ]
    }
   ],
   "source": [
    "bounds=[[0.02,1.5]]*(len(x0)) \n",
    "bounds[sub_indices[-1]] = [1.0,5.0] # change between vowel and consonant\n",
    "#bounds[insert_indices[-1]] = [1.5,5] # change between vowel and consonant\n",
    "#bounds[delete_indices[-1]] = [1.5,5] # change between vowel and consonant\n",
    "\n",
    "bounds[warping_index] = [0.05,5] # warping index\n",
    "bounds[length_compensation_index] = [0.1,3] # length compensation index\n",
    "\n",
    "dd_wpld_xs = {}\n",
    "dd_wpld_dev_scores = {}\n",
    "\n",
    "nbest_multipliers = [0, 5, 10, 15, 50]\n",
    "num_iter_rounds = 10\n",
    "f = IntProgress(min=0, max=len(nbest_multipliers) * num_iter_rounds) # instantiate the bar\n",
    "f.value = 0\n",
    "print(\"Search for optimal parameters with different N-best list lengths\")\n",
    "display(f) # display the bar\n",
    "\n",
    "for n in range(len(nbest_multipliers)):\n",
    "    nbest_multiplier = nbest_multipliers[n]\n",
    "    current_train_items = np.copy((train_items).astype(np.bool))\n",
    "    x1 = 0.4*np.random.rand( x0.shape[0] ) + 0.1\n",
    "    x2 = {'success' : False}\n",
    "    dd_wpld_xs[nbest_multiplier] = {}\n",
    "    dd_wpld_dev_scores[nbest_multiplier] = {} \n",
    "    #print(\"N-best hypotheses: %iL\" % nbest_multiplier)\n",
    "    for iterround in range(num_iter_rounds):\n",
    "        f.value += 1        \n",
    "        compute_Os(x1, nbest_multiplier)\n",
    "        #print(\"             Optimisation round %i\" % (iterround))\n",
    "        x2 = minimize(costfunction, x1, bounds=bounds, options={'disp': False, 'maxiter': 19})\n",
    "        x1 = x2['x']\n",
    "        dd_wpld_xs[nbest_multiplier][iterround] = x1\n",
    "        dd_wpld_hyp = get_scores(x1, devel_items)\n",
    "        dd_wpld_dev_scores[nbest_multiplier][iterround] = np.corrcoef(scores[devel_items[:len(scores)]], dd_wpld_hyp)[0,1]\n",
    "        #print(\"                         Score on dev set: %0.4f\" % dd_wpld_dev_scores[nbest_multiplier][iterround])\n",
    "        if x2['success']:\n",
    "            break\n",
    "        if iterround > 1:\n",
    "            if dd_wpld_dev_scores[nbest_multiplier][iterround] < dd_wpld_dev_scores[nbest_multiplier][iterround-1]:\n",
    "                #print(\"It's not getting better so breaking.\")\n",
    "                break\n",
    "    f.value = num_iter_rounds * (n+1)\n",
    "#print(\"Results on devel set:\")\n",
    "#pprint(dd_wpld_dev_scores)\n",
    "          \n",
    "          \n",
    "print(\"\")\n",
    "ddwpld_best_score = -np.inf\n",
    "ddwpld_best_system = None\n",
    "best_keys = None\n",
    "for k in dd_wpld_dev_scores.keys():\n",
    "    for i in dd_wpld_dev_scores[k].keys():\n",
    "        if dd_wpld_dev_scores[k][i] > ddwpld_best_score:\n",
    "            ddwpld_best_score = dd_wpld_dev_scores[k][i]            \n",
    "            ddwpld_best_system = dd_wpld_xs[k][i]\n",
    "            best_keys = [k,i]\n",
    "print(\"dd-wpld best score:\",ddwpld_best_score)\n",
    "print(\"dd-wpld best keys:\", best_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the 5 runs, I got:\n",
    "\n",
    "* 0.51_ on n-best list of 10/reference phone and 3 iterations\n",
    "* 0.456 on full 51-best list and 7 iterations\n",
    "* 0.458 on n-best list of 10/reference phone and 2 iterations\n",
    "\n",
    "What did you get?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Phoneme Weighted Levenshtein Distance #\n",
    "\n",
    "Here we take the phoneme weights as granted and optimise only the mapping parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search for optimal parameters with different N-best list lengths\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be6738a978b42d78970e584ab907f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=50)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Yey!\n",
      "\n",
      "Base-pwld best score: 0.417294859589439\n",
      "Base-pwld best keys: [50, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bounds=np.zeros([len(x0),2]) \n",
    "bounds[sub_indices,0] = sub_costvector\n",
    "bounds[sub_indices,1] = sub_costvector\n",
    "bounds[ins_indices,0] = ins_costvector\n",
    "bounds[ins_indices,1] = ins_costvector\n",
    "bounds[del_indices,0] = del_costvector\n",
    "bounds[del_indices,1] = del_costvector\n",
    "bounds[warping_index] = [0.05,15] # warping index\n",
    "bounds[length_compensation_index] = [0.1,3] # length compensation index\n",
    "\n",
    "base_wpld_xs = {}\n",
    "base_wpld_dev_scores = {}\n",
    "\n",
    "f = IntProgress(min=0, max=len(nbest_multipliers) * num_iter_rounds) # instantiate the bar\n",
    "f.value = 0\n",
    "print(\"Search for optimal parameters with different N-best list lengths\")\n",
    "display(f) # display the bar\n",
    "\n",
    "\n",
    "for n in range(len(nbest_multipliers)):\n",
    "    nbest_multiplier = nbest_multipliers[n]\n",
    "    current_train_items = np.copy((train_items+1).astype(np.bool))\n",
    "    x1 = 0.4*np.random.rand( x0.shape[0] ) + 0.1\n",
    "    x2 = {'success' : False}\n",
    "    base_wpld_xs[nbest_multiplier] = {}\n",
    "    base_wpld_dev_scores[nbest_multiplier] = {} \n",
    "    #print(\"N-best hypotheses: %iL\" % nbest_multiplier) \n",
    "    for iterround in range(10):\n",
    "        f.value += 1         \n",
    "        compute_Os(x0, nbest_multiplier)\n",
    "        #print(\"             Optimisation round %i\" % (iterround))\n",
    "        x2 = minimize(costfunction, x1, bounds=bounds, options={'disp': True, 'maxiter': 29})\n",
    "        x1 = x2['x']\n",
    "        base_wpld_xs[nbest_multiplier][iterround] = x1\n",
    "        base_wpld_hyp = get_scores(x1, devel_items)\n",
    "        base_wpld_dev_scores[nbest_multiplier][iterround] = np.corrcoef(scores[devel_items[:len(scores)]], base_wpld_hyp)[0,1]\n",
    "        #print(\"                         Score on dev set: %0.4f\" % base_wpld_dev_scores[nbest_multiplier][iterround])\n",
    "        if x2['success']:\n",
    "            break\n",
    "        if iterround > 1:\n",
    "            if base_wpld_dev_scores[nbest_multiplier][iterround] < base_wpld_dev_scores[nbest_multiplier][iterround-1]:\n",
    "                #print(\"It's not getting better so breaking.\")\n",
    "                break\n",
    "    f.value = num_iter_rounds * (n+1)\n",
    "                \n",
    "#print(\"Results on devel set:\")\n",
    "#pprint(base_wpld_dev_scores)\n",
    "          \n",
    "print(\"Done! Yey!\")                    \n",
    "          \n",
    "print(\"\")\n",
    "basewpld_best_score = -np.inf\n",
    "basewpld_best_system = None\n",
    "basewpld_best_keys = None\n",
    "for k in base_wpld_dev_scores.keys():\n",
    "    for i in base_wpld_dev_scores[k].keys():\n",
    "        if base_wpld_dev_scores[k][i] > basewpld_best_score:\n",
    "            basewpld_best_score = base_wpld_dev_scores[k][i]            \n",
    "            basewpld_best_system = base_wpld_xs[k][i]\n",
    "            basewpld_best_keys = [k,i]\n",
    "print(\"Base-pwld best score:\",basewpld_best_score)\n",
    "print(\"Base-pwld best keys:\", basewpld_best_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the 5 runs, I got the best scores \n",
    "\n",
    "* 0.417, using the whole 51-best list.\n",
    "* 0.417, using the whole 51-best list.\n",
    "* 0.417, using the whole 51-best list.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with Support Vector Machines and Random Forests #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for optimal parameters with different N-best list lengths and C and Epsilon values\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0aa4ab15a74be085f52a361c2ff564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=60)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/l/rkarhila/scratch/conda-envs/tf.1.13.1_nogpu/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, yey!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm_xs = {}\n",
    "svm_dev_scores = {}\n",
    "max_iter = 10000\n",
    "\n",
    "\n",
    "cs =  [1,  100, 400]\n",
    "epsilons = [0.01, 0.1, 0.2, 0.5]\n",
    "\n",
    "f = IntProgress(min=0, max=len(nbest_multipliers) * len(cs) * len(epsilons)) # instantiate the bar\n",
    "f.value = 0\n",
    "print(\"Grid search for optimal parameters with different N-best list lengths and C and Epsilon values\")\n",
    "display(f) # display the bar\n",
    "\n",
    "for nbest_multiplier in [0, 5, 10, 15, 50]:\n",
    "    compute_Os(x0, nbest_multiplier)\n",
    "    parameterisation_for_svm = np.hstack([ref_lengths.reshape([-1,1]) ,O_sub, O_ins, O_del])\n",
    "    svm_xs[nbest_multiplier] = {}\n",
    "    svm_dev_scores[nbest_multiplier] = {}    \n",
    "    for c in cs:\n",
    "        svm_xs[nbest_multiplier][c] = {}\n",
    "        svm_dev_scores[nbest_multiplier][c] = {}\n",
    "        for epsilon in epsilons:\n",
    "            f.value += 1\n",
    "            #print(\"Training SVR with nbest_multiplier=%i C=%0.1f, epsilon=%0.3f\" % (nbest_multiplier,c, epsilon))\n",
    "            svm_xs[nbest_multiplier][c][epsilon] = SVR(epsilon=epsilon, C=c, kernel='rbf', degree=3, coef0=0.0, shrinking=True, tol=0.001, cache_size=200, verbose=False, max_iter = max_iter)\n",
    "            svm_xs[nbest_multiplier][c][epsilon].fit( parameterisation_for_svm[current_train_items,:], inv_scores[current_train_items])\n",
    "            svm_hyp = svm_xs[nbest_multiplier][c][epsilon].predict( parameterisation_for_svm[devel_items,:])\n",
    "            svm_dev_scores[nbest_multiplier][c][epsilon] = np.corrcoef(svm_hyp, inv_scores[devel_items])[0,1]\n",
    "            #print(\"Correlation with devel set: %0.3f\" % svm_dev_scores[nbest_multiplier][c][epsilon])\n",
    "print (\"Done, yey!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM best score: 0.4907249296868968\n",
      "SVM best keys: [10, 1, 0.2]\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "svm_best_score = -np.inf\n",
    "svm_best_system = None\n",
    "svm_best_keys = None\n",
    "for k in svm_dev_scores.keys():\n",
    "    for i in svm_dev_scores[k].keys():\n",
    "        for j in svm_dev_scores[k][i].keys():\n",
    "            if svm_dev_scores[k][i][j] > svm_best_score:\n",
    "                svm_best_score = svm_dev_scores[k][i][j]\n",
    "                svm_best_system = svm_xs[k][i][j]\n",
    "                svm_best_keys = [k,i,j]\n",
    "print(\"SVM best score:\",svm_best_score)\n",
    "print(\"SVM best keys:\", svm_best_keys)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that took some time! Grid searching is certainly not optimal but you can't say I didn't put effort in these \"competing technologies\"...\n",
    "\n",
    "Anyway, numbers on the 5 runs: \n",
    "\n",
    "* 0.496 for n-best list of 5/reference phone, C 100 and epsilon 0.2 (!).\n",
    "* 0.489 for n-best list of 10/reference phone, C 1 and epsilon 0.2 (!).\n",
    "* 0.491 for n-best list of 10/reference phone, C 1 and epsilon 0.2 (!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for optimal parameters with different N-best list lengths and estimator and min sample values\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde437828f61469998bb8f9e13a58580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=60)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, yey!\n"
     ]
    }
   ],
   "source": [
    "rf_xs = {}\n",
    "rf_dev_scores = {}\n",
    "\n",
    "f = IntProgress(min=0, max=len(nbest_multipliers) * len(cs) * len(epsilons)) # instantiate the bar\n",
    "f.value = 0\n",
    "print(\"Grid search for optimal parameters with different N-best list lengths and estimator and min sample values\")\n",
    "display(f) # display the bar\n",
    "n_ests = [20, 100,  400]\n",
    "min_sampleses = [1, 10, 20]\n",
    "\n",
    "for nbest_multiplier in nbest_multipliers:\n",
    "    compute_Os(x0, nbest_multiplier)\n",
    "    parameterisation_for_svm = np.hstack([ref_lengths.reshape([-1,1]) ,O_sub, O_ins, O_del])    \n",
    "    rf_xs[nbest_multiplier] = {}\n",
    "    rf_dev_scores[nbest_multiplier] = {}\n",
    "    for n_est in n_ests:\n",
    "        rf_xs[nbest_multiplier][n_est] = {}\n",
    "        rf_dev_scores[nbest_multiplier][n_est] = {}\n",
    "        for min_samples in min_sampleses:\n",
    "            f.value += 1\n",
    "            #print(\"Training random forest with nbest_multiplier=%i number of estimators=%i, min_sample_for_leaf=%i\" % (nbest_multiplier, n_est, min_samples))\n",
    "            #rf_xs[n_est][min_samples] = RandomForestRegressor(n_estimators=n_est, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=1, warm_start=False)\n",
    "            rf_xs[nbest_multiplier][n_est][min_samples] = RandomForestRegressor(n_estimators=n_est, criterion='mse', min_samples_split=2, min_samples_leaf=min_samples, verbose=0)\n",
    "            rf_xs[nbest_multiplier][n_est][min_samples].fit( parameterisation_for_svm[current_train_items,:], inv_scores[current_train_items])\n",
    "            rf_hyp = rf_xs[nbest_multiplier][n_est][min_samples].predict( parameterisation_for_svm[devel_items,:])\n",
    "            rf_dev_scores[nbest_multiplier][n_est][min_samples] = np.corrcoef(rf_hyp, inv_scores[devel_items])[0,1]\n",
    "            #print(\"Correlation with devel set: %0.3f\" % rf_dev_scores[nbest_multiplier][c][epsilon])\n",
    "       \n",
    "print (\"Done, yey!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest best score: 0.5034383906578757\n",
      "Random Forest best keys: [50, 100, 10]\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "rf_best_score = -np.inf\n",
    "rf_best_system = None\n",
    "rf_best_keys = None\n",
    "for k in rf_dev_scores.keys():\n",
    "    for i in rf_dev_scores[k].keys():\n",
    "        for j in rf_dev_scores[k][i].keys():\n",
    "            if rf_dev_scores[k][i][j] > rf_best_score:\n",
    "                rf_best_score = rf_dev_scores[k][i][j]\n",
    "                rf_best_system = rf_xs[k][i][j]\n",
    "                rf_best_keys = [k,i,j]\n",
    "print(\"Random Forest best score:\",rf_best_score)\n",
    "print(\"Random Forest best keys:\", rf_best_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa! \n",
    "\n",
    "I got \n",
    "\n",
    "* 0.494 with n-best list of 5/reference phone, 100 estimators and leaf minimum size of 1.\n",
    "* 0.502 with the full 51-best list, 400 estimators and minimun leaf size of 1\n",
    "* 0.503 with the full 51-best list, 100 estimators and minimun leaf size of 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of systems #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_Os(ddwpld_best_system, 10) #ddwpld_best_keys[0])\n",
    "dd_wpld_test_scores = do_computation(ddwpld_best_system, test_items )\n",
    "\n",
    "compute_Os(basewpld_best_system, basewpld_best_keys[0])\n",
    "base_wpld_test_scores = do_computation(basewpld_best_system, test_items )\n",
    "\n",
    "\n",
    "compute_Os(x0, svm_best_keys[0])\n",
    "parameterisation_for_svm = np.hstack([ref_lengths.reshape([-1,1]) ,O_sub, O_ins, O_del])\n",
    "svm_test_scores = svm_best_system.predict( parameterisation_for_svm[test_items,:])\n",
    "\n",
    "compute_Os(x0, rf_best_keys[0])\n",
    "parameterisation_for_svm = np.hstack([ref_lengths.reshape([-1,1]) ,O_sub, O_ins, O_del])\n",
    "rf_test_scores = rf_best_system.predict( parameterisation_for_svm[test_items,:])\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_test_scores = inv_scores[test_items]\n",
    "\n",
    "correlations = { 'rf' : np.corrcoef(rf_test_scores, ref_test_scores)[0,1],\n",
    "                 'svm' : np.corrcoef(svm_test_scores, ref_test_scores)[0,1],\n",
    "                 'ddwlpd' : np.corrcoef(dd_wpld_test_scores, ref_test_scores)[0,1],\n",
    "                 'basewlpd' : np.corrcoef(base_wpld_test_scores, ref_test_scores)[0,1]}\n",
    "\n",
    "error_vecs = { 'svm': np.abs(svm_test_scores*100-ref_test_scores),\n",
    "                'rf': np.abs(rf_test_scores*100-ref_test_scores),\n",
    "                'ddwpld' : np.abs(dd_wpld_test_scores-ref_test_scores),\n",
    "                'basewlpd' : np.abs(base_wpld_test_scores - ref_test_scores) }\n",
    "\n",
    "mean_errors = { 'svm': np.mean(error_vecs['svm']),\n",
    "                'rf':  np.mean(error_vecs['rf']),\n",
    "                'ddwpld' : np.mean(error_vecs['ddwpld']),\n",
    "                'basewlpd' : np.mean(error_vecs['basewlpd']) }\n",
    "\n",
    "error_std = { 'svm': np.std(error_vecs['svm']),\n",
    "                'rf':  np.std(error_vecs['rf']),\n",
    "                'ddwpld' : np.std(error_vecs['ddwpld']),\n",
    "                'basewlpd' : np.std(error_vecs['basewlpd']) }\n",
    "\n",
    "\n",
    "outliers =  {'svm': np.where(error_vecs['svm']> mean_errors['svm']+2*error_std['svm'])[0],\n",
    "            'rf':  np.where(error_vecs['rf']> mean_errors['rf']+2*error_std['rf'])[0],\n",
    "            'ddwpld' : np.where(error_vecs['ddwpld']> mean_errors['ddwpld']+2*error_std['ddwpld'])[0],\n",
    "            'basewlpd' : np.where(error_vecs['basewlpd']> mean_errors['basewlpd']+2*error_std['basewlpd'])[0]}\n",
    "\n",
    "\n",
    "non_outliers_voted = np.where(np.bincount(np.hstack([outliers['svm'],outliers['rf'],outliers['ddwpld'],outliers['basewlpd']])) <= 1)[0]\n",
    "#non_outliers_voted = np.where(np.bincount(np.hstack([outliers['svm'],outliers['rf'],outliers['ddwpld'],outliers['basewpld']])) <= 0)[0]\n",
    "\n",
    "\n",
    "correlations_outliers_removed = {\n",
    "    'rf' :np.corrcoef(rf_test_scores[non_outliers_voted], ref_test_scores[non_outliers_voted]) [0,1],\n",
    "    'svm' : np.corrcoef(svm_test_scores[non_outliers_voted], ref_test_scores[non_outliers_voted]) [0,1],\n",
    "    'ddwlpd' : np.corrcoef(dd_wpld_test_scores[non_outliers_voted], ref_test_scores[non_outliers_voted]) [0,1],\n",
    "    'basewlpd' : np.corrcoef(base_wpld_test_scores[non_outliers_voted], ref_test_scores[non_outliers_voted]) [0,1],}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlations for all test data:\n",
      "rf              0.509\n",
      "svm             0.517\n",
      "ddwlpd          0.475\n",
      "basewlpd        0.426\n",
      "Correlations for test data where outliers are removed:\n",
      "rf              0.553\n",
      "svm             0.568\n",
      "ddwlpd          0.527\n",
      "basewlpd        0.476\n"
     ]
    }
   ],
   "source": [
    "print(\"Correlations for all test data:\")\n",
    "for k,v in correlations.items():\n",
    "    print(k.ljust(15),\"%0.3f\"%v)\n",
    "print(\"Correlations for test data where outliers are removed:\")\n",
    "for k,v in correlations_outliers_removed.items():\n",
    "    print(k.ljust(15),\"%0.3f\"%v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the first run I got:\n",
    "    \n",
    "Correlations for all test data:\n",
    "\n",
    "* rf           0.496, 0.512, 0.509\n",
    "* svm           0.459, 0.521, 0.517\n",
    "* ddwlpd          0.478, 0.470, 0.475\n",
    "* basewlpd        0.426, 0.427, 0.425\n",
    "\n",
    "\n",
    "Correlations for test data where outliers are removed:\n",
    "\n",
    "* rf              0.537, 0.554, 0.553\n",
    "* svm             0.474, 0.570, 0.568\n",
    "* ddwlpd          0.547, 0.521, 0.527\n",
    "* basewlpd        0.469, 0.476, 0.476\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4198\n",
      "4313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'svm': 22.9864379350438,\n",
       " 'rf': 23.360209473501804,\n",
       " 'ddwpld': 0.21250628045270625,\n",
       " 'basewlpd': 0.2440076002961799}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(non_outliers_voted))\n",
    "print(test_items.sum())\n",
    "error_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train items: 23440\n",
      " Test items: 4313\n",
      "Devel items: 1333\n",
      "Devel item intersect current train items 0\n",
      " Test item intersect current train items 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Train items:\", current_train_items.sum())\n",
    "print(\" Test items:\", test_items.sum())\n",
    "print(\"Devel items:\", devel_items.sum())\n",
    "\n",
    "print(\"Devel item intersect current train items\",len(np.intersect1d(np.where(devel_items==True)[0],np.where(current_train_items==True)[0])))\n",
    "print(\" Test item intersect current train items\",len(np.intersect1d(np.where(test_items==True)[0],np.where(current_train_items==True)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refmap size: 29882\n",
      "Train items: 24236\n",
      " Test items: 4313\n",
      "Devel items: 1333\n",
      "Devel items intersect train items 0\n",
      " Test items intersect train items 0\n",
      "Count of items in refmap: 17764\n",
      "Train items in refmap: 24236\n",
      " Test items in refmap: 4313\n",
      "Devel items in refmap: 1333\n"
     ]
    }
   ],
   "source": [
    "# Check once more that we have not messed up our data:\n",
    "\n",
    "print(\"Refmap size:\", len(refmap))\n",
    "\n",
    "print(\"Train items:\", train_items.sum())\n",
    "print(\" Test items:\", test_items.sum())\n",
    "print(\"Devel items:\", devel_items.sum())\n",
    "\n",
    "print(\"Devel items intersect train items\",len(np.intersect1d(np.where(devel_items==True)[0],np.where(train_items==True)[0])))\n",
    "print(\" Test items intersect train items\",len(np.intersect1d(np.where(test_items==True)[0],np.where(train_items==True)[0])))\n",
    "\n",
    "bins = np.bincount(refmap)\n",
    "print(\"Count of items in refmap:\", bins.shape[0])\n",
    "print(\"Train items in refmap:\", np.bincount(refmap[train_items]).sum())\n",
    "print(\" Test items in refmap:\", np.bincount(refmap[test_items]).sum())\n",
    "print(\"Devel items in refmap:\", np.bincount(refmap[devel_items]).sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
